{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d2f9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '\\Users\\Royal_Tech\\Documents\\Kaggle\\DATA\\HAM10000' already exists.\n",
      "Directory '\\Users\\Royal_Tech\\Documents\\Kaggle\\DATA\\HAM10000_images_part_1' does not exist or is empty.\n",
      "Directory '\\Users\\Royal_Tech\\Documents\\Kaggle\\DATA\\HAM10000_images_part_2' does not exist or is empty.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "directory = r\"\\Users\\Royal_Tech\\Documents\\Kaggle\\DATA\"\n",
    "csv_location = os.path.join(directory, 'HAM10000_metadata.csv')\n",
    "\n",
    "source_directory_1 = os.path.join(directory, 'HAM10000_images_part_1')\n",
    "source_directory_2 = os.path.join(directory, 'HAM10000_images_part_2')\n",
    "\n",
    "# Create HAM10000 directory\n",
    "ham_directory = os.path.join(directory, 'HAM10000')\n",
    "if not os.path.exists(ham_directory):\n",
    "    os.makedirs(ham_directory)\n",
    "else:\n",
    "    print(f\"Directory '{ham_directory}' already exists.\")\n",
    "\n",
    "destination_directory = os.path.join(directory, 'HAM10000/')\n",
    "\n",
    "def move_images(src, dest):\n",
    "    for file in os.listdir(src):\n",
    "        file_path = os.path.join(src, file)\n",
    "        dest_path = os.path.join(dest, file)\n",
    "        shutil.move(file_path, dest_path)\n",
    "\n",
    "# Move images from the first and second source directory to the destination directory\n",
    "if os.path.exists(source_directory_1) and os.listdir(source_directory_1):\n",
    "    move_images(source_directory_1, destination_directory)\n",
    "    shutil.rmtree(source_directory_1)\n",
    "else:\n",
    "    print(f\"Directory '{source_directory_1}' does not exist or is empty.\")\n",
    "\n",
    "if os.path.exists(source_directory_2) and os.listdir(source_directory_2):\n",
    "    move_images(source_directory_2, destination_directory)\n",
    "    shutil.rmtree(source_directory_2)\n",
    "else:\n",
    "    print(f\"Directory '{source_directory_2}' does not exist or is empty.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5151d04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '\\Users\\Royal_Tech\\Documents\\Kaggle\\DATA\\HAM10000/bkl' already exists.\n",
      "Directory '\\Users\\Royal_Tech\\Documents\\Kaggle\\DATA\\HAM10000/nv' already exists.\n",
      "Directory '\\Users\\Royal_Tech\\Documents\\Kaggle\\DATA\\HAM10000/df' already exists.\n",
      "Directory '\\Users\\Royal_Tech\\Documents\\Kaggle\\DATA\\HAM10000/mel' already exists.\n",
      "Directory '\\Users\\Royal_Tech\\Documents\\Kaggle\\DATA\\HAM10000/vasc' already exists.\n",
      "Directory '\\Users\\Royal_Tech\\Documents\\Kaggle\\DATA\\HAM10000/bcc' already exists.\n",
      "Directory '\\Users\\Royal_Tech\\Documents\\Kaggle\\DATA\\HAM10000/akiec' already exists.\n"
     ]
    }
   ],
   "source": [
    "classes = ['bkl', 'nv', 'df', 'mel', 'vasc', 'bcc', 'akiec']\n",
    "\n",
    "for subfolder in classes:\n",
    "    subfolder_path = os.path.join(destination_directory, subfolder)\n",
    "    if not os.path.exists(subfolder_path):\n",
    "        os.makedirs(subfolder_path)\n",
    "    else:\n",
    "        print(f\"Directory '{subfolder_path}' already exists.\")\n",
    "\n",
    "main_folder = destination_directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd827bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image manipulation not needed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if len(os.listdir(r\"\\Users\\Royal_Tech\\Documents\\Kaggle\\DATA\\HAM10000\\bkl\"))!=0:\n",
    "    print('Image manipulation not needed')\n",
    "else: \n",
    "    for line in open(csv_location).readlines()[1:]:\n",
    "        split_line = line.split(',');\n",
    "        img_file = split_line[1];\n",
    "        tumor_type = split_line[2];\n",
    "\n",
    "        if(tumor_type == 'mel'):\n",
    "            shutil.move(\n",
    "                main_folder + img_file + \".jpg\",\n",
    "                main_folder + \"mel/\" + img_file + \".jpg\",\n",
    "            )\n",
    "        elif(tumor_type == 'bkl'):\n",
    "            shutil.move(\n",
    "                main_folder + img_file + \".jpg\",\n",
    "                main_folder +  \"bkl/\" + img_file + \".jpg\",\n",
    "            )\n",
    "        elif(tumor_type == 'nv'):\n",
    "            shutil.move(\n",
    "                main_folder + img_file + \".jpg\",\n",
    "                main_folder +  \"nv/\" + img_file + \".jpg\",\n",
    "            )\n",
    "        elif(tumor_type == 'df'):\n",
    "            shutil.move(\n",
    "                main_folder + img_file + \".jpg\",\n",
    "                main_folder + \"df/\" + img_file + \".jpg\",\n",
    "            )\n",
    "        elif(tumor_type == 'vasc'):\n",
    "            shutil.move(\n",
    "                main_folder + img_file + \".jpg\",\n",
    "                main_folder + \"vasc/\" + img_file + \".jpg\",\n",
    "            )\n",
    "        elif(tumor_type == 'bcc'):\n",
    "            shutil.move(\n",
    "                main_folder + img_file + \".jpg\",\n",
    "                main_folder + \"bcc/\" + img_file + \".jpg\",\n",
    "            )\n",
    "        elif(tumor_type == 'akiec'):\n",
    "            shutil.move(\n",
    "                main_folder + img_file + \".jpg\",\n",
    "                main_folder + \"akiec/\" + img_file + \".jpg\",\n",
    "            )\n",
    "        else:\n",
    "            shutil.move(\n",
    "                main_folder + img_file + \".jpg\",\n",
    "                main_folder + \"benign/\"+ img_file + \".jpg\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28ac78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = r\"\\Users\\Royal_Tech\\Documents\\Kaggle\\DATA\\HAM10000\"\n",
    "classes = ['bkl', 'nv', 'df', 'mel', 'vasc', 'bcc', 'akiec']\n",
    "\n",
    "image_width = 450\n",
    "image_height = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f35523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Royal_Tech\\anaconda3\\envs\\tf\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10015 files belonging to 7 classes.\n",
      "Using 9014 files for training.\n",
      "Using 1001 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "training, validation  = tf.keras.preprocessing.image_dataset_from_directory (\n",
    "    folder,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=classes,\n",
    "    color_mode='rgb',\n",
    "    image_size=(image_width, image_height),\n",
    "    shuffle=True,\n",
    "    validation_split=0.1,\n",
    "    seed=42,\n",
    "    interpolation='bilinear',\n",
    "    verbose=True,\n",
    "    subset=\"both\",\n",
    "    batch_size=32\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b0eb7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Royal_Tech\\anaconda3\\envs\\tf\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\Royal_Tech\\AppData\\Local\\Temp\\ipykernel_32740\\2394515639.py:19: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  MobileNetV2(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\", input_shape=(224,224,3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(400,600,3)),\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.Resizing(224,224),\n",
    "    data_augmentation,\n",
    "    MobileNetV2(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg',\n",
    "    ),\n",
    "    layers.Dense(7, activation='softmax')  \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy','precision','recall']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27af426a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "\u001b[1m 36/282\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:46\u001b[0m 3s/step - accuracy: 0.5468 - loss: 1.3375 - precision: 0.7268 - recall: 0.4386"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model.fit(\n\u001b[32m      2\u001b[39m     training,\n\u001b[32m      3\u001b[39m     validation_data=(validation),\n\u001b[32m      4\u001b[39m     epochs=\u001b[32m11\u001b[39m,\n\u001b[32m      5\u001b[39m     batch_size=\u001b[32m32\u001b[39m,\n\u001b[32m      6\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Royal_Tech\\anaconda3\\envs\\tf\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Royal_Tech\\anaconda3\\envs\\tf\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28mself\u001b[39m.train_function(iterator)\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Royal_Tech\\anaconda3\\envs\\tf\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = multi_step_on_iterator(iterator)\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Royal_Tech\\anaconda3\\envs\\tf\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Royal_Tech\\anaconda3\\envs\\tf\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28mself\u001b[39m._call(*args, **kwds)\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Royal_Tech\\anaconda3\\envs\\tf\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = tracing_compilation.call_function(\n\u001b[32m    879\u001b[39m     args, kwds, \u001b[38;5;28mself\u001b[39m._variable_creation_config\n\u001b[32m    880\u001b[39m )\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Royal_Tech\\anaconda3\\envs\\tf\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m function._call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    140\u001b[39m     flat_inputs, captured_inputs=function.captured_inputs\n\u001b[32m    141\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Royal_Tech\\anaconda3\\envs\\tf\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inference_function.call_preflattened(args)\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Royal_Tech\\anaconda3\\envs\\tf\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28mself\u001b[39m.call_flat(*args)\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Royal_Tech\\anaconda3\\envs\\tf\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m._bound_context.call_function(\n\u001b[32m    252\u001b[39m         \u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    253\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    254\u001b[39m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.function_type.flat_outputs),\n\u001b[32m    255\u001b[39m     )\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Royal_Tech\\anaconda3\\envs\\tf\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = execute.execute(\n\u001b[32m   1689\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1690\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   1691\u001b[39m       inputs=tensor_inputs,\n\u001b[32m   1692\u001b[39m       attrs=attrs,\n\u001b[32m   1693\u001b[39m       ctx=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1694\u001b[39m   )\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Royal_Tech\\anaconda3\\envs\\tf\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    training,\n",
    "    validation_data=(validation),\n",
    "    epochs=11,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "851b111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "10c4fda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10015 entries, 0 to 10014\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   lesion_id     10015 non-null  object \n",
      " 1   image_id      10015 non-null  object \n",
      " 2   dx            10015 non-null  object \n",
      " 3   dx_type       10015 non-null  object \n",
      " 4   age           9958 non-null   float64\n",
      " 5   sex           10015 non-null  object \n",
      " 6   localization  10015 non-null  object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 547.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82064604",
   "metadata": {},
   "source": [
    "FILLING UP THE AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "777d674d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "False    10015\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Royal_Tech\\AppData\\Local\\Temp\\ipykernel_32740\\1472435033.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[\"age\"].fillna(mean, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "mean = data[\"age\"].mean()\n",
    "data[\"age\"].fillna(mean, inplace=True)\n",
    "print(data[\"age\"].isna().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2579537c",
   "metadata": {},
   "source": [
    "FILL UP SEX OF THE PATIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6039bff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female' 'unknown']\n",
      "sex\n",
      "male       5406\n",
      "female     4552\n",
      "unknown      57\n",
      "Name: count, dtype: int64\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(data[\"sex\"].unique())\n",
    "print(data[\"sex\"].value_counts())\n",
    "print(len(data[data[\"sex\"]==\"unknown\"]))\n",
    "\n",
    "\n",
    "choices = [\"male\",\"female\"]\n",
    "probs = [0.54, 0.46]\n",
    "\n",
    "\n",
    "missing_idx = data[data[\"sex\"]==\"unknown\"].index\n",
    "amount_of_indexes = len(missing_idx)\n",
    "\n",
    "fills = np.random.choice(choices,size=amount_of_indexes, p=probs)\n",
    "\n",
    "\n",
    "data.loc[missing_idx, \"sex\"] = fills\n",
    "\n",
    "sex_mapping = {\n",
    "    \"male\": 1.0,\n",
    "    \"female\": 0.0\n",
    "}\n",
    "\n",
    "data[\"sex\"] = data[\"sex\"].map(sex_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "06d911e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10015 entries, 0 to 10014\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   lesion_id     10015 non-null  object \n",
      " 1   image_id      10015 non-null  object \n",
      " 2   dx            10015 non-null  object \n",
      " 3   dx_type       10015 non-null  object \n",
      " 4   age           10015 non-null  float64\n",
      " 5   sex           10015 non-null  float64\n",
      " 6   localization  10015 non-null  object \n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 547.8+ KB\n",
      "None\n",
      "['histo' 'consensus' 'confocal' 'follow_up']\n",
      "['scalp' 'ear' 'face' 'back' 'trunk' 'chest' 'upper extremity' 'abdomen'\n",
      " 'unknown' 'lower extremity' 'genital' 'neck' 'hand' 'foot' 'acral']\n"
     ]
    }
   ],
   "source": [
    "print(data.info())\n",
    "dx_types = data[\"dx_type\"].unique()\n",
    "localizations = data[\"localization\"].unique()\n",
    "\n",
    "print(dx_types)\n",
    "print(localizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d8953801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        HAM_0000118\n",
      "1        HAM_0000118\n",
      "2        HAM_0002730\n",
      "3        HAM_0002730\n",
      "4        HAM_0001466\n",
      "            ...     \n",
      "10010    HAM_0002867\n",
      "10011    HAM_0002867\n",
      "10012    HAM_0002867\n",
      "10013    HAM_0000239\n",
      "10014    HAM_0003521\n",
      "Name: lesion_id, Length: 10015, dtype: object\n",
      "0        ISIC_0027419\n",
      "1        ISIC_0025030\n",
      "2        ISIC_0026769\n",
      "3        ISIC_0025661\n",
      "4        ISIC_0031633\n",
      "             ...     \n",
      "10010    ISIC_0033084\n",
      "10011    ISIC_0033550\n",
      "10012    ISIC_0033536\n",
      "10013    ISIC_0032854\n",
      "10014    ISIC_0032258\n",
      "Name: image_id, Length: 10015, dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10015 entries, 0 to 10014\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   dx_type       10015 non-null  object \n",
      " 1   age           10015 non-null  float64\n",
      " 2   sex           10015 non-null  float64\n",
      " 3   localization  10015 non-null  object \n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 313.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data[\"lesion_id\"])\n",
    "print(data[\"image_id\"])\n",
    "\n",
    "keyDf = data[[\"lesion_id\",\"image_id\"]]\n",
    "\n",
    "csv_Y = data[\"dx\"]\n",
    "df = data.drop(columns=[\"lesion_id\",\"image_id\",\"dx\"])\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9308d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def oneHotEncodeColumns(df, columns):\n",
    "    for column in columns:\n",
    "        encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    \n",
    "        tmp_shape = df[column].to_numpy().reshape(-1,1)\n",
    "        matrix = encoder.fit_transform(tmp_shape)\n",
    "        column_names = encoder.get_feature_names_out([column])\n",
    "        newDf = pd.DataFrame(matrix,columns=column_names, index=df.index)\n",
    "        df.drop(column, axis=1, inplace=True)\n",
    "    \n",
    "        df = pd.concat([newDf,df], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = oneHotEncodeColumns(df, [\"localization\",\"dx_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d7341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10015 entries, 0 to 10014\n",
      "Data columns (total 21 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   dx_type_confocal              10015 non-null  float64\n",
      " 1   dx_type_consensus             10015 non-null  float64\n",
      " 2   dx_type_follow_up             10015 non-null  float64\n",
      " 3   dx_type_histo                 10015 non-null  float64\n",
      " 4   localization_abdomen          10015 non-null  float64\n",
      " 5   localization_acral            10015 non-null  float64\n",
      " 6   localization_back             10015 non-null  float64\n",
      " 7   localization_chest            10015 non-null  float64\n",
      " 8   localization_ear              10015 non-null  float64\n",
      " 9   localization_face             10015 non-null  float64\n",
      " 10  localization_foot             10015 non-null  float64\n",
      " 11  localization_genital          10015 non-null  float64\n",
      " 12  localization_hand             10015 non-null  float64\n",
      " 13  localization_lower extremity  10015 non-null  float64\n",
      " 14  localization_neck             10015 non-null  float64\n",
      " 15  localization_scalp            10015 non-null  float64\n",
      " 16  localization_trunk            10015 non-null  float64\n",
      " 17  localization_unknown          10015 non-null  float64\n",
      " 18  localization_upper extremity  10015 non-null  float64\n",
      " 19  age                           10015 non-null  float64\n",
      " 20  sex                           10015 non-null  float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 1.6 MB\n",
      "None\n",
      "   dx_type_confocal  dx_type_consensus  dx_type_follow_up  dx_type_histo  \\\n",
      "0               0.0                0.0                0.0            1.0   \n",
      "1               0.0                0.0                0.0            1.0   \n",
      "2               0.0                0.0                0.0            1.0   \n",
      "3               0.0                0.0                0.0            1.0   \n",
      "4               0.0                0.0                0.0            1.0   \n",
      "\n",
      "   localization_abdomen  localization_acral  localization_back  \\\n",
      "0                   0.0                 0.0                0.0   \n",
      "1                   0.0                 0.0                0.0   \n",
      "2                   0.0                 0.0                0.0   \n",
      "3                   0.0                 0.0                0.0   \n",
      "4                   0.0                 0.0                0.0   \n",
      "\n",
      "   localization_chest  localization_ear  localization_face  ...  \\\n",
      "0                 0.0               0.0                0.0  ...   \n",
      "1                 0.0               0.0                0.0  ...   \n",
      "2                 0.0               0.0                0.0  ...   \n",
      "3                 0.0               0.0                0.0  ...   \n",
      "4                 0.0               1.0                0.0  ...   \n",
      "\n",
      "   localization_genital  localization_hand  localization_lower extremity  \\\n",
      "0                   0.0                0.0                           0.0   \n",
      "1                   0.0                0.0                           0.0   \n",
      "2                   0.0                0.0                           0.0   \n",
      "3                   0.0                0.0                           0.0   \n",
      "4                   0.0                0.0                           0.0   \n",
      "\n",
      "   localization_neck  localization_scalp  localization_trunk  \\\n",
      "0                0.0                 1.0                 0.0   \n",
      "1                0.0                 1.0                 0.0   \n",
      "2                0.0                 1.0                 0.0   \n",
      "3                0.0                 1.0                 0.0   \n",
      "4                0.0                 0.0                 0.0   \n",
      "\n",
      "   localization_unknown  localization_upper extremity   age  sex  \n",
      "0                   0.0                           0.0  80.0  1.0  \n",
      "1                   0.0                           0.0  80.0  1.0  \n",
      "2                   0.0                           0.0  80.0  1.0  \n",
      "3                   0.0                           0.0  80.0  1.0  \n",
      "4                   0.0                           0.0  75.0  1.0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "0          bkl\n",
      "1          bkl\n",
      "2          bkl\n",
      "3          bkl\n",
      "4          bkl\n",
      "         ...  \n",
      "10010    akiec\n",
      "10011    akiec\n",
      "10012    akiec\n",
      "10013    akiec\n",
      "10014      mel\n",
      "Name: dx, Length: 10015, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d584104",
   "metadata": {},
   "source": [
    "Scale down the age a bit so its not the biggest fucking value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b457165c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0.941176\n",
      "1        0.941176\n",
      "2        0.941176\n",
      "3        0.941176\n",
      "4        0.882353\n",
      "           ...   \n",
      "10010    0.470588\n",
      "10011    0.470588\n",
      "10012    0.470588\n",
      "10013    0.941176\n",
      "10014    0.823529\n",
      "Name: age, Length: 10015, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[\"age\"] = scaler.fit_transform(df[[\"age\"]])\n",
    "print(df[\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5f7aa432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Royal_Tech\\anaconda3\\envs\\tf\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "tmp_shape = data[\"dx\"].to_numpy().reshape(-1,1)\n",
    "Y = encoder.fit_transform(tmp_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a36e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 0 0 4]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "14ae2dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.75298\n",
      "[1]\tvalidation_0-mlogloss:1.61213\n",
      "[2]\tvalidation_0-mlogloss:1.50103\n",
      "[3]\tvalidation_0-mlogloss:1.41014\n",
      "[4]\tvalidation_0-mlogloss:1.33375\n",
      "[5]\tvalidation_0-mlogloss:1.26855\n",
      "[6]\tvalidation_0-mlogloss:1.21224\n",
      "[7]\tvalidation_0-mlogloss:1.16268\n",
      "[8]\tvalidation_0-mlogloss:1.11934\n",
      "[9]\tvalidation_0-mlogloss:1.08110\n",
      "[10]\tvalidation_0-mlogloss:1.04719\n",
      "[11]\tvalidation_0-mlogloss:1.01709\n",
      "[12]\tvalidation_0-mlogloss:0.99010\n",
      "[13]\tvalidation_0-mlogloss:0.96592\n",
      "[14]\tvalidation_0-mlogloss:0.94434\n",
      "[15]\tvalidation_0-mlogloss:0.92493\n",
      "[16]\tvalidation_0-mlogloss:0.90731\n",
      "[17]\tvalidation_0-mlogloss:0.89151\n",
      "[18]\tvalidation_0-mlogloss:0.87723\n",
      "[19]\tvalidation_0-mlogloss:0.86449\n",
      "[20]\tvalidation_0-mlogloss:0.85257\n",
      "[21]\tvalidation_0-mlogloss:0.84215\n",
      "[22]\tvalidation_0-mlogloss:0.83256\n",
      "[23]\tvalidation_0-mlogloss:0.82381\n",
      "[24]\tvalidation_0-mlogloss:0.81604\n",
      "[25]\tvalidation_0-mlogloss:0.80859\n",
      "[26]\tvalidation_0-mlogloss:0.80186\n",
      "[27]\tvalidation_0-mlogloss:0.79586\n",
      "[28]\tvalidation_0-mlogloss:0.79025\n",
      "[29]\tvalidation_0-mlogloss:0.78506\n",
      "[30]\tvalidation_0-mlogloss:0.78051\n",
      "[31]\tvalidation_0-mlogloss:0.77614\n",
      "[32]\tvalidation_0-mlogloss:0.77225\n",
      "[33]\tvalidation_0-mlogloss:0.76875\n",
      "[34]\tvalidation_0-mlogloss:0.76514\n",
      "[35]\tvalidation_0-mlogloss:0.76221\n",
      "[36]\tvalidation_0-mlogloss:0.75940\n",
      "[37]\tvalidation_0-mlogloss:0.75694\n",
      "[38]\tvalidation_0-mlogloss:0.75428\n",
      "[39]\tvalidation_0-mlogloss:0.75207\n",
      "[40]\tvalidation_0-mlogloss:0.75008\n",
      "[41]\tvalidation_0-mlogloss:0.74831\n",
      "[42]\tvalidation_0-mlogloss:0.74658\n",
      "[43]\tvalidation_0-mlogloss:0.74500\n",
      "[44]\tvalidation_0-mlogloss:0.74317\n",
      "[45]\tvalidation_0-mlogloss:0.74182\n",
      "[46]\tvalidation_0-mlogloss:0.74039\n",
      "[47]\tvalidation_0-mlogloss:0.73917\n",
      "[48]\tvalidation_0-mlogloss:0.73809\n",
      "[49]\tvalidation_0-mlogloss:0.73711\n",
      "[50]\tvalidation_0-mlogloss:0.73607\n",
      "[51]\tvalidation_0-mlogloss:0.73531\n",
      "[52]\tvalidation_0-mlogloss:0.73448\n",
      "[53]\tvalidation_0-mlogloss:0.73344\n",
      "[54]\tvalidation_0-mlogloss:0.73283\n",
      "[55]\tvalidation_0-mlogloss:0.73203\n",
      "[56]\tvalidation_0-mlogloss:0.73112\n",
      "[57]\tvalidation_0-mlogloss:0.73039\n",
      "[58]\tvalidation_0-mlogloss:0.72973\n",
      "[59]\tvalidation_0-mlogloss:0.72900\n",
      "[60]\tvalidation_0-mlogloss:0.72844\n",
      "[61]\tvalidation_0-mlogloss:0.72780\n",
      "[62]\tvalidation_0-mlogloss:0.72742\n",
      "[63]\tvalidation_0-mlogloss:0.72690\n",
      "[64]\tvalidation_0-mlogloss:0.72645\n",
      "[65]\tvalidation_0-mlogloss:0.72595\n",
      "[66]\tvalidation_0-mlogloss:0.72538\n",
      "[67]\tvalidation_0-mlogloss:0.72510\n",
      "[68]\tvalidation_0-mlogloss:0.72474\n",
      "[69]\tvalidation_0-mlogloss:0.72446\n",
      "[70]\tvalidation_0-mlogloss:0.72414\n",
      "[71]\tvalidation_0-mlogloss:0.72378\n",
      "[72]\tvalidation_0-mlogloss:0.72359\n",
      "[73]\tvalidation_0-mlogloss:0.72332\n",
      "[74]\tvalidation_0-mlogloss:0.72308\n",
      "[75]\tvalidation_0-mlogloss:0.72284\n",
      "[76]\tvalidation_0-mlogloss:0.72263\n",
      "[77]\tvalidation_0-mlogloss:0.72228\n",
      "[78]\tvalidation_0-mlogloss:0.72216\n",
      "[79]\tvalidation_0-mlogloss:0.72196\n",
      "[80]\tvalidation_0-mlogloss:0.72186\n",
      "[81]\tvalidation_0-mlogloss:0.72169\n",
      "[82]\tvalidation_0-mlogloss:0.72148\n",
      "[83]\tvalidation_0-mlogloss:0.72130\n",
      "[84]\tvalidation_0-mlogloss:0.72117\n",
      "[85]\tvalidation_0-mlogloss:0.72088\n",
      "[86]\tvalidation_0-mlogloss:0.72051\n",
      "[87]\tvalidation_0-mlogloss:0.72037\n",
      "[88]\tvalidation_0-mlogloss:0.72025\n",
      "[89]\tvalidation_0-mlogloss:0.72017\n",
      "[90]\tvalidation_0-mlogloss:0.71989\n",
      "[91]\tvalidation_0-mlogloss:0.71954\n",
      "[92]\tvalidation_0-mlogloss:0.71935\n",
      "[93]\tvalidation_0-mlogloss:0.71918\n",
      "[94]\tvalidation_0-mlogloss:0.71909\n",
      "[95]\tvalidation_0-mlogloss:0.71886\n",
      "[96]\tvalidation_0-mlogloss:0.71856\n",
      "[97]\tvalidation_0-mlogloss:0.71849\n",
      "[98]\tvalidation_0-mlogloss:0.71833\n",
      "[99]\tvalidation_0-mlogloss:0.71812\n",
      "[100]\tvalidation_0-mlogloss:0.71806\n",
      "[101]\tvalidation_0-mlogloss:0.71789\n",
      "[102]\tvalidation_0-mlogloss:0.71778\n",
      "[103]\tvalidation_0-mlogloss:0.71761\n",
      "[104]\tvalidation_0-mlogloss:0.71751\n",
      "[105]\tvalidation_0-mlogloss:0.71745\n",
      "[106]\tvalidation_0-mlogloss:0.71731\n",
      "[107]\tvalidation_0-mlogloss:0.71712\n",
      "[108]\tvalidation_0-mlogloss:0.71709\n",
      "[109]\tvalidation_0-mlogloss:0.71691\n",
      "[110]\tvalidation_0-mlogloss:0.71691\n",
      "[111]\tvalidation_0-mlogloss:0.71673\n",
      "[112]\tvalidation_0-mlogloss:0.71647\n",
      "[113]\tvalidation_0-mlogloss:0.71639\n",
      "[114]\tvalidation_0-mlogloss:0.71627\n",
      "[115]\tvalidation_0-mlogloss:0.71610\n",
      "[116]\tvalidation_0-mlogloss:0.71605\n",
      "[117]\tvalidation_0-mlogloss:0.71595\n",
      "[118]\tvalidation_0-mlogloss:0.71600\n",
      "[119]\tvalidation_0-mlogloss:0.71586\n",
      "[120]\tvalidation_0-mlogloss:0.71566\n",
      "[121]\tvalidation_0-mlogloss:0.71542\n",
      "[122]\tvalidation_0-mlogloss:0.71522\n",
      "[123]\tvalidation_0-mlogloss:0.71521\n",
      "[124]\tvalidation_0-mlogloss:0.71493\n",
      "[125]\tvalidation_0-mlogloss:0.71479\n",
      "[126]\tvalidation_0-mlogloss:0.71468\n",
      "[127]\tvalidation_0-mlogloss:0.71453\n",
      "[128]\tvalidation_0-mlogloss:0.71440\n",
      "[129]\tvalidation_0-mlogloss:0.71417\n",
      "[130]\tvalidation_0-mlogloss:0.71409\n",
      "[131]\tvalidation_0-mlogloss:0.71388\n",
      "[132]\tvalidation_0-mlogloss:0.71355\n",
      "[133]\tvalidation_0-mlogloss:0.71350\n",
      "[134]\tvalidation_0-mlogloss:0.71339\n",
      "[135]\tvalidation_0-mlogloss:0.71308\n",
      "[136]\tvalidation_0-mlogloss:0.71286\n",
      "[137]\tvalidation_0-mlogloss:0.71277\n",
      "[138]\tvalidation_0-mlogloss:0.71266\n",
      "[139]\tvalidation_0-mlogloss:0.71259\n",
      "[140]\tvalidation_0-mlogloss:0.71244\n",
      "[141]\tvalidation_0-mlogloss:0.71247\n",
      "[142]\tvalidation_0-mlogloss:0.71231\n",
      "[143]\tvalidation_0-mlogloss:0.71213\n",
      "[144]\tvalidation_0-mlogloss:0.71198\n",
      "[145]\tvalidation_0-mlogloss:0.71184\n",
      "[146]\tvalidation_0-mlogloss:0.71185\n",
      "[147]\tvalidation_0-mlogloss:0.71177\n",
      "[148]\tvalidation_0-mlogloss:0.71169\n",
      "[149]\tvalidation_0-mlogloss:0.71164\n",
      "[150]\tvalidation_0-mlogloss:0.71167\n",
      "[151]\tvalidation_0-mlogloss:0.71152\n",
      "[152]\tvalidation_0-mlogloss:0.71138\n",
      "[153]\tvalidation_0-mlogloss:0.71130\n",
      "[154]\tvalidation_0-mlogloss:0.71132\n",
      "[155]\tvalidation_0-mlogloss:0.71108\n",
      "[156]\tvalidation_0-mlogloss:0.71099\n",
      "[157]\tvalidation_0-mlogloss:0.71089\n",
      "[158]\tvalidation_0-mlogloss:0.71066\n",
      "[159]\tvalidation_0-mlogloss:0.71067\n",
      "[160]\tvalidation_0-mlogloss:0.71064\n",
      "[161]\tvalidation_0-mlogloss:0.71051\n",
      "[162]\tvalidation_0-mlogloss:0.71053\n",
      "[163]\tvalidation_0-mlogloss:0.71045\n",
      "[164]\tvalidation_0-mlogloss:0.71041\n",
      "[165]\tvalidation_0-mlogloss:0.71030\n",
      "[166]\tvalidation_0-mlogloss:0.71022\n",
      "[167]\tvalidation_0-mlogloss:0.71009\n",
      "[168]\tvalidation_0-mlogloss:0.70996\n",
      "[169]\tvalidation_0-mlogloss:0.70989\n",
      "[170]\tvalidation_0-mlogloss:0.70992\n",
      "[171]\tvalidation_0-mlogloss:0.70987\n",
      "[172]\tvalidation_0-mlogloss:0.70972\n",
      "[173]\tvalidation_0-mlogloss:0.70964\n",
      "[174]\tvalidation_0-mlogloss:0.70956\n",
      "[175]\tvalidation_0-mlogloss:0.70947\n",
      "[176]\tvalidation_0-mlogloss:0.70938\n",
      "[177]\tvalidation_0-mlogloss:0.70937\n",
      "[178]\tvalidation_0-mlogloss:0.70922\n",
      "[179]\tvalidation_0-mlogloss:0.70918\n",
      "[180]\tvalidation_0-mlogloss:0.70916\n",
      "[181]\tvalidation_0-mlogloss:0.70922\n",
      "[182]\tvalidation_0-mlogloss:0.70929\n",
      "[183]\tvalidation_0-mlogloss:0.70933\n",
      "[184]\tvalidation_0-mlogloss:0.70931\n",
      "[185]\tvalidation_0-mlogloss:0.70925\n",
      "[186]\tvalidation_0-mlogloss:0.70924\n",
      "[187]\tvalidation_0-mlogloss:0.70920\n",
      "[188]\tvalidation_0-mlogloss:0.70923\n",
      "[189]\tvalidation_0-mlogloss:0.70921\n",
      "[190]\tvalidation_0-mlogloss:0.70918\n",
      "[191]\tvalidation_0-mlogloss:0.70911\n",
      "[192]\tvalidation_0-mlogloss:0.70897\n",
      "[193]\tvalidation_0-mlogloss:0.70894\n",
      "[194]\tvalidation_0-mlogloss:0.70878\n",
      "[195]\tvalidation_0-mlogloss:0.70871\n",
      "[196]\tvalidation_0-mlogloss:0.70864\n",
      "[197]\tvalidation_0-mlogloss:0.70848\n",
      "[198]\tvalidation_0-mlogloss:0.70852\n",
      "[199]\tvalidation_0-mlogloss:0.70855\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-10 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-10 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-10 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-10 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-10 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None, num_class=7, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None, num_class=7, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='mlogloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None, num_class=7, ...)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df, Y, stratify=Y, random_state=42)\n",
    "\n",
    "csv_model = xgb.XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=7,\n",
    "    eval_metric='mlogloss',\n",
    "    learning_rate=0.1,\n",
    "    max_depth=4,\n",
    "    random_state=42,\n",
    "    n_estimators=200\n",
    ")\n",
    "csv_model.fit(X_train, Y_train, eval_set=[(X_test,Y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7163f3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 1.77\n",
      "Mean Absolute Error (MAE): 0.62\n",
      "R^2 Score: 0.1697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "predictions = csv_model.predict(X_test)\n",
    "mse = mean_squared_error(Y_test,predictions)\n",
    "mae = mean_absolute_error(Y_test,predictions)\n",
    "r2 = r2_score(Y_test, predictions)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86ef190",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_model.save_model(\"xgboost.json\")\n",
    "model.save(\"cigmacigmaboy.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
